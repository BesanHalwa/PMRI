{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "360d36c6-3187-41ce-9dca-037c47839864",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-05-28 15:42:58.267014: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-05-28 15:42:58.267044: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-05-28 15:42:58.268044: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-05-28 15:42:58.273353: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2025-05-28 15:42:58.780339: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2025-05-28 15:42:59.456276: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.456505: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.491131: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.491413: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.491596: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.491768: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.633560: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.633776: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.633958: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.634128: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.634308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.634479: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.642144: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.642345: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.642524: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.642697: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.642875: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.643032: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 22272 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:21:00.0, compute capability: 8.9\n",
      "2025-05-28 15:42:59.643401: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2025-05-28 15:42:59.643551: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 21867 MB memory:  -> device: 1, name: NVIDIA GeForce RTX 4090, pci bus id: 0000:41:00.0, compute capability: 8.9\n",
      "2025-05-28 15:43:00,301 - INFO - Initialized generator\n",
      "2025-05-28 15:43:00,571 - INFO - Train images shape: (2088, 256, 256, 1)\n",
      "2025-05-28 15:43:00,571 - INFO - Train ROI shape: (2088, 256, 256, 6)\n",
      "2025-05-28 15:43:00,572 - INFO - Val images shape: (312, 256, 256, 1)\n",
      "2025-05-28 15:43:00,572 - INFO - Val ROI shape: (312, 256, 256, 6)\n",
      "2025-05-28 15:43:00,642 - INFO - Train ROI min: 0, max: 1\n",
      "2025-05-28 15:43:00,653 - INFO - Val ROI min: 0, max: 1\n",
      "2025-05-28 15:43:13,625 - INFO - Train ROI unique values: [0 1]\n",
      "2025-05-28 15:43:14,257 - INFO - Train images shape: (2088, 256, 256, 1)\n",
      "2025-05-28 15:43:14,258 - INFO - Train ROI shape: (2088, 256, 256, 6)\n",
      "2025-05-28 15:43:14,258 - INFO - Val images shape: (312, 256, 256, 1)\n",
      "2025-05-28 15:43:14,258 - INFO - Val ROI shape: (312, 256, 256, 6)\n",
      "2025-05-28 15:43:14,328 - INFO - Train ROI min: 0, max: 1\n",
      "2025-05-28 15:43:14,339 - INFO - Val ROI min: 0, max: 1\n",
      "2025-05-28 15:43:27,314 - INFO - Train ROI unique values: [0 1]\n",
      "2025-05-28 15:43:30.816132: W tensorflow/core/kernels/data/cache_dataset_ops.cc:858] The calling iterator did not fully read the dataset being cached. In order to avoid unexpected truncation of the dataset, the partially cached contents of the dataset  will be discarded. This can happen if you have an input pipeline similar to `dataset.cache().take(k).repeat()`. You should use `dataset.take(k).cache().repeat()` instead.\n",
      "2025-05-28 15:43:30.867268: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n",
      "2025-05-28 15:43:30.923197: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-05-28 15:43:33.713845: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2025-05-28 15:43:39,057 - INFO - Restored generator weights from ./training_checkpoints/ckpt-47\n",
      "2025-05-28 15:43:39,323 - INFO - Train images shape: (2088, 256, 256, 1)\n",
      "2025-05-28 15:43:39,324 - INFO - Train ROI shape: (2088, 256, 256, 6)\n",
      "2025-05-28 15:43:39,324 - INFO - Val images shape: (312, 256, 256, 1)\n",
      "2025-05-28 15:43:39,325 - INFO - Val ROI shape: (312, 256, 256, 6)\n",
      "2025-05-28 15:43:39,398 - INFO - Train ROI min: 0, max: 1\n",
      "2025-05-28 15:43:39,409 - INFO - Val ROI min: 0, max: 1\n",
      "2025-05-28 15:43:52,386 - INFO - Train ROI unique values: [0 1]\n",
      "2025-05-28 15:43:55,192 - INFO - Starting epoch 1/500\n",
      "2025-05-28 15:43:57.488897: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:961] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/sequential_1/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2025-05-28 15:44:00.229386: I external/local_xla/xla/service/service.cc:168] XLA service 0x78b944280330 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2025-05-28 15:44:00.229410: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (0): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-05-28 15:44:00.229415: I external/local_xla/xla/service/service.cc:176]   StreamExecutor device (1): NVIDIA GeForce RTX 4090, Compute Capability 8.9\n",
      "2025-05-28 15:44:00.232722: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1748418240.303601  378839 device_compiler.h:186] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n",
      "2025-05-28 15:44:42,312 - INFO - Epoch 1: Train Loss = 1.2837, Val Loss = 0.6027, Time = 47.12 sec\n",
      "2025-05-28 15:44:43,217 - INFO - Saved best checkpoint for epoch 1\n",
      "2025-05-28 15:44:43,218 - INFO - Starting epoch 2/500\n",
      "2025-05-28 15:44:50,758 - INFO - Epoch 2: Train Loss = 0.5573, Val Loss = 0.5262, Time = 7.54 sec\n",
      "2025-05-28 15:44:51,361 - INFO - Saved best checkpoint for epoch 2\n",
      "2025-05-28 15:44:51,361 - INFO - Starting epoch 3/500\n",
      "2025-05-28 15:44:58,919 - INFO - Epoch 3: Train Loss = 1.2899, Val Loss = 0.6129, Time = 7.56 sec\n",
      "2025-05-28 15:44:58,921 - INFO - Starting epoch 4/500\n",
      "2025-05-28 15:45:06,446 - INFO - Epoch 4: Train Loss = 1.0068, Val Loss = 0.5999, Time = 7.52 sec\n",
      "2025-05-28 15:45:06,449 - INFO - Starting epoch 5/500\n",
      "2025-05-28 15:45:13,973 - INFO - Epoch 5: Train Loss = 0.9467, Val Loss = 0.5345, Time = 7.52 sec\n",
      "2025-05-28 15:45:14,563 - INFO - Saved periodic checkpoint for epoch 5\n",
      "2025-05-28 15:45:14,564 - INFO - Starting epoch 6/500\n",
      "2025-05-28 15:45:22,070 - INFO - Epoch 6: Train Loss = 0.9856, Val Loss = 0.5117, Time = 7.51 sec\n",
      "2025-05-28 15:45:22,657 - INFO - Saved best checkpoint for epoch 6\n",
      "2025-05-28 15:45:22,658 - INFO - Starting epoch 7/500\n",
      "2025-05-28 15:45:30,155 - INFO - Epoch 7: Train Loss = 0.8519, Val Loss = 0.5592, Time = 7.50 sec\n",
      "2025-05-28 15:45:30,158 - INFO - Starting epoch 8/500\n",
      "2025-05-28 15:45:37,700 - INFO - Epoch 8: Train Loss = 0.8354, Val Loss = 0.5608, Time = 7.54 sec\n",
      "2025-05-28 15:45:37,703 - INFO - Starting epoch 9/500\n",
      "2025-05-28 15:45:45,245 - INFO - Epoch 9: Train Loss = 0.8225, Val Loss = 0.5691, Time = 7.54 sec\n",
      "2025-05-28 15:45:45,248 - INFO - Starting epoch 10/500\n",
      "2025-05-28 15:45:52,787 - INFO - Epoch 10: Train Loss = 0.8129, Val Loss = 0.5760, Time = 7.54 sec\n",
      "2025-05-28 15:45:53,378 - INFO - Saved periodic checkpoint for epoch 10\n",
      "2025-05-28 15:45:53,379 - INFO - Starting epoch 11/500\n",
      "2025-05-28 15:46:00,904 - INFO - Epoch 11: Train Loss = 0.8027, Val Loss = 0.5802, Time = 7.52 sec\n",
      "2025-05-28 15:46:00,907 - INFO - Starting epoch 12/500\n",
      "2025-05-28 15:46:08,442 - INFO - Epoch 12: Train Loss = 0.7929, Val Loss = 0.5815, Time = 7.53 sec\n",
      "2025-05-28 15:46:08,445 - INFO - Starting epoch 13/500\n",
      "2025-05-28 15:46:15,978 - INFO - Epoch 13: Train Loss = 0.7837, Val Loss = 0.5802, Time = 7.53 sec\n",
      "2025-05-28 15:46:15,981 - INFO - Starting epoch 14/500\n",
      "2025-05-28 15:46:23,529 - INFO - Epoch 14: Train Loss = 0.7772, Val Loss = 0.5774, Time = 7.55 sec\n",
      "2025-05-28 15:46:23,532 - INFO - Starting epoch 15/500\n",
      "2025-05-28 15:46:31,073 - INFO - Epoch 15: Train Loss = 0.7712, Val Loss = 0.5763, Time = 7.54 sec\n",
      "2025-05-28 15:46:31,662 - INFO - Saved periodic checkpoint for epoch 15\n",
      "2025-05-28 15:46:31,662 - INFO - Starting epoch 16/500\n",
      "2025-05-28 15:46:39,212 - INFO - Epoch 16: Train Loss = 0.7637, Val Loss = 0.5798, Time = 7.55 sec\n",
      "2025-05-28 15:46:39,214 - INFO - Starting epoch 17/500\n",
      "2025-05-28 15:46:46,747 - INFO - Epoch 17: Train Loss = 0.7591, Val Loss = 0.5902, Time = 7.53 sec\n",
      "2025-05-28 15:46:46,749 - INFO - Starting epoch 18/500\n",
      "2025-05-28 15:46:54,263 - INFO - Epoch 18: Train Loss = 0.7521, Val Loss = 0.6163, Time = 7.51 sec\n",
      "2025-05-28 15:46:54,265 - INFO - Starting epoch 19/500\n",
      "2025-05-28 15:47:01,793 - INFO - Epoch 19: Train Loss = 0.7473, Val Loss = 0.7032, Time = 7.53 sec\n",
      "2025-05-28 15:47:01,795 - INFO - Starting epoch 20/500\n",
      "2025-05-28 15:47:09,318 - INFO - Epoch 20: Train Loss = 0.7410, Val Loss = 0.4340, Time = 7.52 sec\n",
      "2025-05-28 15:47:09,906 - INFO - Saved best checkpoint for epoch 20\n",
      "2025-05-28 15:47:10,481 - INFO - Saved periodic checkpoint for epoch 20\n",
      "2025-05-28 15:47:10,482 - INFO - Starting epoch 21/500\n",
      "2025-05-28 15:47:18,000 - INFO - Epoch 21: Train Loss = 0.7380, Val Loss = 0.7320, Time = 7.52 sec\n",
      "2025-05-28 15:47:18,003 - INFO - Starting epoch 22/500\n",
      "2025-05-28 15:47:25,539 - INFO - Epoch 22: Train Loss = 0.7312, Val Loss = 0.4159, Time = 7.54 sec\n",
      "2025-05-28 15:47:26,136 - INFO - Saved best checkpoint for epoch 22\n",
      "2025-05-28 15:47:26,137 - INFO - Starting epoch 23/500\n",
      "2025-05-28 15:47:33,661 - INFO - Epoch 23: Train Loss = 0.7267, Val Loss = 0.4995, Time = 7.52 sec\n",
      "2025-05-28 15:47:33,664 - INFO - Starting epoch 24/500\n",
      "2025-05-28 15:47:41,208 - INFO - Epoch 24: Train Loss = 0.7229, Val Loss = 0.5231, Time = 7.54 sec\n",
      "2025-05-28 15:47:41,211 - INFO - Starting epoch 25/500\n",
      "2025-05-28 15:47:48,749 - INFO - Epoch 25: Train Loss = 0.7188, Val Loss = 0.5346, Time = 7.54 sec\n",
      "2025-05-28 15:47:49,344 - INFO - Saved periodic checkpoint for epoch 25\n",
      "2025-05-28 15:47:49,344 - INFO - Starting epoch 26/500\n",
      "2025-05-28 15:47:56,867 - INFO - Epoch 26: Train Loss = 0.7149, Val Loss = 0.5415, Time = 7.52 sec\n",
      "2025-05-28 15:47:56,870 - INFO - Starting epoch 27/500\n",
      "2025-05-28 15:48:04,417 - INFO - Epoch 27: Train Loss = 0.7107, Val Loss = 0.5457, Time = 7.55 sec\n",
      "2025-05-28 15:48:04,419 - INFO - Starting epoch 28/500\n",
      "2025-05-28 15:48:11,958 - INFO - Epoch 28: Train Loss = 0.7074, Val Loss = 0.5490, Time = 7.54 sec\n",
      "2025-05-28 15:48:11,961 - INFO - Starting epoch 29/500\n",
      "2025-05-28 15:48:19,504 - INFO - Epoch 29: Train Loss = 0.7048, Val Loss = 0.5512, Time = 7.54 sec\n",
      "2025-05-28 15:48:19,506 - INFO - Starting epoch 30/500\n",
      "2025-05-28 15:48:27,032 - INFO - Epoch 30: Train Loss = 0.7002, Val Loss = 0.5529, Time = 7.53 sec\n",
      "2025-05-28 15:48:27,618 - INFO - Saved periodic checkpoint for epoch 30\n",
      "2025-05-28 15:48:27,619 - INFO - Starting epoch 31/500\n",
      "2025-05-28 15:48:35,127 - INFO - Epoch 31: Train Loss = 0.6952, Val Loss = 0.5539, Time = 7.51 sec\n",
      "2025-05-28 15:48:35,129 - INFO - Starting epoch 32/500\n",
      "2025-05-28 15:48:42,662 - INFO - Epoch 32: Train Loss = 0.6927, Val Loss = 0.5540, Time = 7.53 sec\n",
      "2025-05-28 15:48:42,664 - INFO - Starting epoch 33/500\n",
      "2025-05-28 15:48:50,178 - INFO - Epoch 33: Train Loss = 0.6892, Val Loss = 0.5534, Time = 7.51 sec\n",
      "2025-05-28 15:48:50,180 - INFO - Starting epoch 34/500\n",
      "2025-05-28 15:48:57,725 - INFO - Epoch 34: Train Loss = 0.6853, Val Loss = 0.5511, Time = 7.54 sec\n",
      "2025-05-28 15:48:57,728 - INFO - Starting epoch 35/500\n",
      "2025-05-28 15:49:05,273 - INFO - Epoch 35: Train Loss = 0.6833, Val Loss = 0.5469, Time = 7.55 sec\n",
      "2025-05-28 15:49:05,860 - INFO - Saved periodic checkpoint for epoch 35\n",
      "2025-05-28 15:49:05,861 - INFO - Starting epoch 36/500\n",
      "2025-05-28 15:49:13,412 - INFO - Epoch 36: Train Loss = 0.6792, Val Loss = 0.5387, Time = 7.55 sec\n",
      "2025-05-28 15:49:13,415 - INFO - Starting epoch 37/500\n",
      "2025-05-28 15:49:20,955 - INFO - Epoch 37: Train Loss = 0.6768, Val Loss = 0.5222, Time = 7.54 sec\n",
      "2025-05-28 15:49:20,958 - INFO - Starting epoch 38/500\n",
      "2025-05-28 15:49:28,481 - INFO - Epoch 38: Train Loss = 0.6738, Val Loss = 0.4646, Time = 7.52 sec\n",
      "2025-05-28 15:49:28,484 - INFO - Starting epoch 39/500\n",
      "2025-05-28 15:49:36,052 - INFO - Epoch 39: Train Loss = 0.6712, Val Loss = -0.2414, Time = 7.57 sec\n",
      "2025-05-28 15:49:36,666 - INFO - Saved best checkpoint for epoch 39\n",
      "2025-05-28 15:49:36,667 - INFO - Starting epoch 40/500\n",
      "2025-05-28 15:49:44,207 - INFO - Epoch 40: Train Loss = 0.6673, Val Loss = 0.6209, Time = 7.54 sec\n",
      "2025-05-28 15:49:44,793 - INFO - Saved periodic checkpoint for epoch 40\n",
      "2025-05-28 15:49:44,794 - INFO - Starting epoch 41/500\n",
      "2025-05-28 15:49:52,321 - INFO - Epoch 41: Train Loss = 0.6641, Val Loss = 0.5885, Time = 7.53 sec\n",
      "2025-05-28 15:49:52,324 - INFO - Starting epoch 42/500\n",
      "2025-05-28 15:49:59,854 - INFO - Epoch 42: Train Loss = 0.6611, Val Loss = 0.5767, Time = 7.53 sec\n",
      "2025-05-28 15:49:59,857 - INFO - Starting epoch 43/500\n",
      "2025-05-28 15:50:07,384 - INFO - Epoch 43: Train Loss = 0.6588, Val Loss = 0.5705, Time = 7.53 sec\n",
      "2025-05-28 15:50:07,387 - INFO - Starting epoch 44/500\n",
      "2025-05-28 15:50:14,923 - INFO - Epoch 44: Train Loss = 0.6563, Val Loss = 0.5669, Time = 7.54 sec\n",
      "2025-05-28 15:50:14,925 - INFO - Starting epoch 45/500\n",
      "2025-05-28 15:50:22,459 - INFO - Epoch 45: Train Loss = 0.6537, Val Loss = 0.5645, Time = 7.53 sec\n",
      "2025-05-28 15:50:23,054 - INFO - Saved periodic checkpoint for epoch 45\n",
      "2025-05-28 15:50:23,055 - INFO - Starting epoch 46/500\n",
      "2025-05-28 15:50:30,572 - INFO - Epoch 46: Train Loss = 0.6496, Val Loss = 0.5631, Time = 7.52 sec\n",
      "2025-05-28 15:50:30,575 - INFO - Starting epoch 47/500\n",
      "2025-05-28 15:50:38,100 - INFO - Epoch 47: Train Loss = 0.6478, Val Loss = 0.5628, Time = 7.52 sec\n",
      "2025-05-28 15:50:38,103 - INFO - Starting epoch 48/500\n",
      "2025-05-28 15:50:45,634 - INFO - Epoch 48: Train Loss = 0.6454, Val Loss = 0.5630, Time = 7.53 sec\n",
      "2025-05-28 15:50:45,636 - INFO - Starting epoch 49/500\n",
      "2025-05-28 15:50:53,167 - INFO - Epoch 49: Train Loss = 0.6425, Val Loss = 0.5635, Time = 7.53 sec\n",
      "2025-05-28 15:50:53,170 - INFO - Starting epoch 50/500\n",
      "2025-05-28 15:51:00,723 - INFO - Epoch 50: Train Loss = 0.6396, Val Loss = 0.5639, Time = 7.55 sec\n",
      "2025-05-28 15:51:01,315 - INFO - Saved periodic checkpoint for epoch 50\n",
      "2025-05-28 15:51:01,316 - INFO - Starting epoch 51/500\n",
      "2025-05-28 15:51:08,857 - INFO - Epoch 51: Train Loss = 0.6376, Val Loss = 0.5643, Time = 7.54 sec\n",
      "2025-05-28 15:51:08,860 - INFO - Starting epoch 52/500\n",
      "2025-05-28 15:51:16,401 - INFO - Epoch 52: Train Loss = 0.6336, Val Loss = 0.5644, Time = 7.54 sec\n",
      "2025-05-28 15:51:16,404 - INFO - Starting epoch 53/500\n",
      "2025-05-28 15:51:23,949 - INFO - Epoch 53: Train Loss = 0.6312, Val Loss = 0.5642, Time = 7.54 sec\n",
      "2025-05-28 15:51:23,952 - INFO - Starting epoch 54/500\n",
      "2025-05-28 15:51:31,481 - INFO - Epoch 54: Train Loss = 0.6282, Val Loss = 0.5640, Time = 7.53 sec\n",
      "2025-05-28 15:51:31,484 - INFO - Starting epoch 55/500\n",
      "2025-05-28 15:51:39,031 - INFO - Epoch 55: Train Loss = 0.6254, Val Loss = 0.5636, Time = 7.55 sec\n",
      "2025-05-28 15:51:39,637 - INFO - Saved periodic checkpoint for epoch 55\n",
      "2025-05-28 15:51:39,637 - INFO - Starting epoch 56/500\n",
      "2025-05-28 15:51:47,164 - INFO - Epoch 56: Train Loss = 0.6238, Val Loss = 0.5631, Time = 7.53 sec\n",
      "2025-05-28 15:51:47,167 - INFO - Starting epoch 57/500\n",
      "2025-05-28 15:51:54,725 - INFO - Epoch 57: Train Loss = 0.6205, Val Loss = 0.5626, Time = 7.56 sec\n",
      "2025-05-28 15:51:54,728 - INFO - Starting epoch 58/500\n",
      "2025-05-28 15:52:02,282 - INFO - Epoch 58: Train Loss = 0.6171, Val Loss = 0.5620, Time = 7.55 sec\n",
      "2025-05-28 15:52:02,285 - INFO - Starting epoch 59/500\n",
      "2025-05-28 15:52:09,831 - INFO - Epoch 59: Train Loss = 0.6140, Val Loss = 0.5614, Time = 7.55 sec\n",
      "2025-05-28 15:52:09,834 - INFO - Starting epoch 60/500\n",
      "2025-05-28 15:52:17,393 - INFO - Epoch 60: Train Loss = 0.6112, Val Loss = 0.5608, Time = 7.56 sec\n",
      "2025-05-28 15:52:17,985 - INFO - Saved periodic checkpoint for epoch 60\n",
      "2025-05-28 15:52:17,986 - INFO - Starting epoch 61/500\n",
      "2025-05-28 15:52:25,512 - INFO - Epoch 61: Train Loss = 0.6086, Val Loss = 0.5600, Time = 7.53 sec\n",
      "2025-05-28 15:52:25,515 - INFO - Starting epoch 62/500\n",
      "2025-05-28 15:52:33,052 - INFO - Epoch 62: Train Loss = 0.6062, Val Loss = 0.5590, Time = 7.54 sec\n",
      "2025-05-28 15:52:33,055 - INFO - Starting epoch 63/500\n",
      "2025-05-28 15:52:40,578 - INFO - Epoch 63: Train Loss = 0.6043, Val Loss = 0.5581, Time = 7.52 sec\n",
      "2025-05-28 15:52:40,581 - INFO - Starting epoch 64/500\n",
      "2025-05-28 15:52:48,115 - INFO - Epoch 64: Train Loss = 0.6016, Val Loss = 0.5571, Time = 7.53 sec\n",
      "2025-05-28 15:52:48,118 - INFO - Early stopping triggered after 25 epochs without improvement\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/besanhalwa/Eshan/project1_PMRI/pmri_env/lib/python3.10/site-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "2025-05-28 15:52:48,120 - WARNING - Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/home/besanhalwa/Eshan/project1_PMRI/pmri_env/lib/python3.10/site-packages/keras/src/initializers/__init__.py:144: UserWarning: The `keras.initializers.serialize()` API should only be used for objects of type `keras.initializers.Initializer`. Found an instance of type <class 'tensorflow.python.ops.init_ops_v2.RandomNormal'>, which may lead to improper serialization.\n",
      "  warnings.warn(\n",
      "2025-05-28 15:52:48,454 - INFO - Fine-tuning completed and generator saved\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import logging\n",
    "from pathlib import Path\n",
    "from model import Generator  # Import Generator from model.py\n",
    "import time\n",
    "\n",
    "# Configure logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    handlers=[\n",
    "        logging.FileHandler('finetune.log'),\n",
    "        logging.StreamHandler()\n",
    "    ]\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Constants\n",
    "IMG_WIDTH = 256\n",
    "IMG_HEIGHT = 256\n",
    "INPUT_CHANNELS = 1  # Single-channel grayscale input\n",
    "OUTPUT_CHANNELS = 6  # One-hot encoded ROI (6 classes)\n",
    "BATCH_SIZE = 128\n",
    "BUFFER_SIZE = 1000\n",
    "EPOCHS = 500\n",
    "WEIGHTS_DIR = './training_checkpoints'\n",
    "LOG_DIR = './logs'\n",
    "DATA_DIR = '/home/besanhalwa/Eshan/project1_PMRI/Data/npy_tech_pmri_no_aug_leftRightSplit/'\n",
    "\n",
    "# Loss functions\n",
    "def dice_loss_channel_wise(y_true, y_pred, smooth=1e-6):\n",
    "    \"\"\"\n",
    "    Compute channel-wise Dice loss for multi-class segmentation.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    y_true_f = tf.reshape(y_true, (-1, y_true.shape[-1]))\n",
    "    y_pred_f = tf.reshape(y_pred, (-1, y_pred.shape[-1]))\n",
    "    intersection = tf.reduce_sum(y_true_f * y_pred_f, axis=0)\n",
    "    union = tf.reduce_sum(y_true_f, axis=0) + tf.reduce_sum(y_pred_f, axis=0)\n",
    "    dice = (2. * intersection + smooth) / (union + smooth)\n",
    "    dice_loss_per_channel = 1 - dice\n",
    "    return tf.reduce_mean(dice_loss_per_channel)\n",
    "\n",
    "def pixel_wise_binary_crossentropy_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Compute pixel-wise binary cross-entropy loss for multi-class segmentation.\n",
    "    \"\"\"\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    y_pred = tf.cast(y_pred, tf.float32)\n",
    "    bce_loss = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n",
    "    loss_per_channel = bce_loss(y_true, y_pred)\n",
    "    return tf.reduce_mean(loss_per_channel)\n",
    "\n",
    "def combined_loss(y_true, y_pred, alpha=0.5):\n",
    "    \"\"\"\n",
    "    Combined loss function: Binary Cross-Entropy Loss + Channel-wise Dice Loss.\n",
    "    \"\"\"\n",
    "    bce_loss = pixel_wise_binary_crossentropy_loss(y_true, y_pred)\n",
    "    dice_loss = dice_loss_channel_wise(y_true, y_pred)\n",
    "    total_loss = alpha * bce_loss + (1 - alpha) * dice_loss\n",
    "    return total_loss\n",
    "\n",
    "# Load datasets\n",
    "def load_npy_datasets():\n",
    "    try:\n",
    "        train_images = np.load(os.path.join(DATA_DIR, 'train_images.npy'))  # Shape: (312, 256, 256)\n",
    "        train_roi = np.load(os.path.join(DATA_DIR, 'train_masks_hot_encoded.npy'))  # Shape: (312, 256, 256)\n",
    "        val_images = np.load(os.path.join(DATA_DIR, 'val_images.npy'))  # Shape: (416, 256, 256)\n",
    "        val_roi = np.load(os.path.join(DATA_DIR, 'val_masks_hot_encoded.npy'))  # Shape: (416, 256, 256)\n",
    "        \n",
    "        # Ensure images have 1 channel\n",
    "        if train_images.ndim == 3:\n",
    "            train_images = np.expand_dims(train_images, axis=-1)\n",
    "        if val_images.ndim == 3:\n",
    "            val_images = np.expand_dims(val_images, axis=-1)\n",
    "        \n",
    "        # Check for NaN values\n",
    "        if np.any(np.isnan(train_images)) or np.any(np.isnan(val_images)):\n",
    "            logger.error(\"NaN values found in input images\")\n",
    "            raise ValueError(\"NaN values in input images\")\n",
    "        if np.any(np.isnan(train_roi)) or np.any(np.isnan(val_roi)):\n",
    "            logger.error(\"NaN values found in ROI masks\")\n",
    "            raise ValueError(\"NaN values in ROI masks\")\n",
    "        \n",
    "        # Log ROI details\n",
    "        logger.info(f\"Train images shape: {train_images.shape}\")\n",
    "        logger.info(f\"Train ROI shape: {train_roi.shape}\")\n",
    "        logger.info(f\"Val images shape: {val_images.shape}\")\n",
    "        logger.info(f\"Val ROI shape: {val_roi.shape}\")\n",
    "        logger.info(f\"Train ROI min: {np.min(train_roi)}, max: {np.max(train_roi)}\")\n",
    "        logger.info(f\"Val ROI min: {np.min(val_roi)}, max: {np.max(val_roi)}\")\n",
    "        unique_values = np.unique(train_roi)\n",
    "        logger.info(f\"Train ROI unique values: {unique_values[:10]}{'...' if len(unique_values) > 10 else ''}\")\n",
    "        \n",
    "        # Validate ROI class labels\n",
    "        if not np.all((train_roi >= 0) & (train_roi <= OUTPUT_CHANNELS)):\n",
    "            logger.error(\"Train ROI contains invalid class labels\")\n",
    "            raise ValueError(\"Invalid class labels in train_roi\")\n",
    "        if not np.all((val_roi >= 0) & (val_roi <= OUTPUT_CHANNELS)):\n",
    "            logger.error(\"Val ROI contains invalid class labels\")\n",
    "            raise ValueError(\"Invalid class labels in val_roi\")\n",
    "        \n",
    "        # Convert integer labels to one-hot encoded\n",
    "        #train_roi = tf.one_hot(train_roi, depth=OUTPUT_CHANNELS).numpy().astype(np.float32)\n",
    "        #val_roi = tf.one_hot(val_roi, depth=OUTPUT_CHANNELS).numpy().astype(np.float32)\n",
    "        \n",
    "        return (train_images.astype(np.float32), train_roi), (val_images.astype(np.float32), val_roi)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load datasets: {e}\")\n",
    "        raise\n",
    "\n",
    "# Data preprocessing\n",
    "def normalize(input_image, real_image):\n",
    "    input_image = tf.cast(input_image, tf.float32)\n",
    "    input_image = (input_image / 127.5) - 1\n",
    "    return input_image, real_image\n",
    "\n",
    "# Create tf.data datasets\n",
    "def create_datasets(train_data, val_data):\n",
    "    train_images, train_roi = train_data\n",
    "    val_images, val_roi = val_data\n",
    "    \n",
    "    train_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_roi))\n",
    "    val_dataset = tf.data.Dataset.from_tensor_slices((val_images, val_roi))\n",
    "    \n",
    "    train_dataset = (train_dataset\n",
    "                     .cache()\n",
    "                     .map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                     .shuffle(BUFFER_SIZE)\n",
    "                     .batch(BATCH_SIZE)\n",
    "                     .prefetch(tf.data.AUTOTUNE))\n",
    "    \n",
    "    val_dataset = (val_dataset\n",
    "                   .cache()\n",
    "                   .map(normalize, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "                   .batch(BATCH_SIZE)\n",
    "                   .prefetch(tf.data.AUTOTUNE))\n",
    "    \n",
    "    return train_dataset, val_dataset\n",
    "\n",
    "# Training step for fine-tuning (generator only)\n",
    "@tf.function\n",
    "def train_step(input_image, target, generator, optimizer):\n",
    "    with tf.GradientTape() as tape:\n",
    "        gen_output = generator(input_image, training=True)\n",
    "        loss = combined_loss(target, gen_output)\n",
    "    gradients = tape.gradient(loss, generator.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, generator.trainable_variables))\n",
    "    return loss\n",
    "\n",
    "# Validation function\n",
    "def validate(val_ds, generator):\n",
    "    val_loss = 0.0\n",
    "    num_batches = 0\n",
    "    for input_image, target in val_ds:\n",
    "        gen_output = generator(input_image, training=False)\n",
    "        loss = combined_loss(target, gen_output)\n",
    "        val_loss += loss.numpy()\n",
    "        num_batches += 1\n",
    "    return val_loss / num_batches\n",
    "\n",
    "# Fine-tuning function\n",
    "def fit(train_ds, val_ds, generator, optimizer, epochs):\n",
    "    best_val_loss = float('inf')\n",
    "    patience = 25\n",
    "    wait = 0\n",
    "    \n",
    "    steps_per_epoch = tf.data.experimental.cardinality(train_ds).numpy()\n",
    "    checkpoint_prefix = os.path.join(WEIGHTS_DIR, \"ckpt\")\n",
    "    checkpoint = tf.train.Checkpoint(generator_optimizer=optimizer, generator=generator)\n",
    "    \n",
    "    summary_writer = tf.summary.create_file_writer(\n",
    "        os.path.join(LOG_DIR, \"fit\", datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "    )\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        logger.info(f\"Starting epoch {epoch + 1}/{epochs}\")\n",
    "        start = time.time()\n",
    "        \n",
    "        # Training\n",
    "        total_loss = 0.0\n",
    "        for step, (input_image, target) in enumerate(train_ds):\n",
    "            loss = train_step(input_image, target, generator, optimizer)\n",
    "            total_loss += loss.numpy()\n",
    "            if (step + 1) % 100 == 0:\n",
    "                logger.info(f\"Step {step + 1}/{steps_per_epoch}: Loss = {loss.numpy():.4f}\")\n",
    "        \n",
    "        avg_train_loss = total_loss / steps_per_epoch\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = validate(val_ds, generator)\n",
    "        logger.info(f\"Epoch {epoch + 1}: Train Loss = {avg_train_loss:.4f}, Val Loss = {val_loss:.4f}, Time = {time.time() - start:.2f} sec\")\n",
    "        \n",
    "        # Logging to TensorBoard\n",
    "        with summary_writer.as_default():\n",
    "            tf.summary.scalar('train_loss', avg_train_loss, step=epoch)\n",
    "            tf.summary.scalar('val_loss', val_loss, step=epoch)\n",
    "        \n",
    "        # Checkpointing: Save best model\n",
    "        if val_loss < best_val_loss and not np.isnan(val_loss):\n",
    "            best_val_loss = val_loss\n",
    "            checkpoint.save(file_prefix='./finetuned_weights' + \"fineTuned_best\")\n",
    "            logger.info(f\"Saved best checkpoint for epoch {epoch + 1}\")\n",
    "            wait = 0\n",
    "        else:\n",
    "            wait += 1\n",
    "        \n",
    "        # Checkpointing: Save every 5 epochs\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            checkpoint.save(file_prefix=checkpoint_prefix + f\"_epoch_{epoch + 1}\")\n",
    "            logger.info(f\"Saved periodic checkpoint for epoch {epoch + 1}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if wait >= patience:\n",
    "            logger.info(f\"Early stopping triggered after {patience} epochs without improvement\")\n",
    "            break\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    try:\n",
    "        # Create directories\n",
    "        Path(WEIGHTS_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        Path(LOG_DIR).mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        # Load model\n",
    "        generator = Generator()\n",
    "        logger.info(\"Initialized generator\")\n",
    "        \n",
    "        # Check model output for NaN\n",
    "        train_ds = create_datasets(load_npy_datasets()[0], load_npy_datasets()[1])[0]\n",
    "        input_image = next(iter(train_ds.take(1)))[0]\n",
    "        gen_output = generator(input_image, training=False)\n",
    "        if tf.math.reduce_any(tf.math.is_nan(gen_output)):\n",
    "            logger.error(\"NaN found in generator output\")\n",
    "            raise ValueError(\"NaN found in generator output\")\n",
    "        \n",
    "        # Load checkpoint\n",
    "        checkpoint = tf.train.Checkpoint(generator=generator)\n",
    "        checkpoint_path = os.path.join(WEIGHTS_DIR, 'ckpt-47')\n",
    "        if not Path(checkpoint_path + '.index').exists():\n",
    "            raise FileNotFoundError(f\"Checkpoint file {checkpoint_path} not found\")\n",
    "        checkpoint.restore(checkpoint_path).expect_partial()\n",
    "        logger.info(f\"Restored generator weights from {checkpoint_path}\")\n",
    "        \n",
    "        # Load data\n",
    "        train_data, val_data = load_npy_datasets()\n",
    "        train_ds, val_ds = create_datasets(train_data, val_data)\n",
    "        \n",
    "        # Optimizer\n",
    "        optimizer = tf.keras.optimizers.Adam(learning_rate=1e-4, beta_1=0.5)\n",
    "        \n",
    "        # Fine-tune generator\n",
    "        fit(train_ds, val_ds, generator, optimizer, EPOCHS)\n",
    "        \n",
    "        # Save final model\n",
    "        generator.save(os.path.join(DATA_DIR, 'generator_finetuned.h5'))\n",
    "        logger.info(\"Fine-tuning completed and generator saved\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        logger.error(f\"Process failed: {e}\")\n",
    "        raise\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9006f66-0ef5-4eea-96fe-86c534701fd3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
